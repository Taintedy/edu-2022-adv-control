{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320d66ac",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#333333; text-align:center; line-height: 0;\"> <img style=\"right;\" src=\"logo.png\" width=18% height=18%> Advanced Control | Assignment 2 \n",
    "</h1>\n",
    "<br/><br/>\n",
    "\n",
    "**First, familiarize yourself with [Rcognita](https://github.com/AIDynamicAction/rcognita) if you have not already done so. This assignment is based on this framework, so it's better to have an intuition about what's going on behind the scenes.**\n",
    "\n",
    "The goal of this assignment is to implement a classic **MPC** controller, described in the section 1.2, namely, `_actor_cost` and `_actor_optimizer` methods.\n",
    "\n",
    "___Total points:___ 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752ad66",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 1: Introduction to model predictive control (MPC) </h2>\n",
    "\n",
    "***\n",
    "###  <font color=\"blue\"> 1.1 Intuition behind MPC </font>\n",
    "**MPC** is one of the most popular methods of obtaining the optimal controller and, in fact, is an industry standard.\n",
    "Let us start from the most reasonable question. Why should we care about **MPC**? Why do we even need that thing? Are there any problems that naturally lead to the development of such a model?\n",
    "\n",
    "In fact, yes. There are infinitely many applications of **MPC**, including petroleum extraction, agricultural facilities, automatic assembly and so on. But let us take a look at the development of such a type of machines that are impressive not only to an expert in the field - humanoid robots. If you've ever seen a video of Boston Dynamics' humanoid robots, you've probably wondered, how do the engineers made it work? How does such a complex machine make those precise movements so that it is capable of performing acrobatics that already exceeds the abilities of a typical human in some aspects (i.e. backflip)?\n",
    "\n",
    "The answer is, you guessed it, **MPC**. \n",
    "\n",
    "The performance of the modern robots comes with its cost. The problem of generating control for any robot requires:\n",
    "\n",
    "- real time performance, as there are in general almost no stable states in the robot's movement, and all the calculations should be performed quickly\n",
    "- optimizing a complex composite cost to a certain time horizon in order to follow the high-level plan\n",
    "- (in some cases) discrete-continuous optimization, which is difficult\n",
    "- taking into account various types of constraints, i.e.\n",
    "    1. torque and angle limits for the servomotors (in a form of inequality)\n",
    "    2. functional constraints following from the problem statement, that do not always allow for an analytical solution \n",
    "    3. also there could be constraints on foot placement, body placement, slippery surfaces, etc.\n",
    "    4. constraints of the limbs non-intersection (if this is a case)\n",
    "\n",
    "All in all, such a problem could lack a closed form solution, like $\\boldsymbol u = \\boldsymbol f(\\text{state}, \\text{target})$.\n",
    "\n",
    "One of the most fundamental important ways to obtain an optimal controller is __MPC__. \n",
    "\n",
    "* __MPC-like algorithms__ are ones of the few that can handle very complex constraints, including functional, nonlinear, nonconvex, etc.\n",
    "\n",
    "Informally speaking, algorithms that generate control for a complex dynamical system typically have to be predictive. And taking the system model into account helps along the way. In order to optimize an objective along the trajectory, we could try to estimate the system behaviour in the future. This is litearlly what **MPC** does. With that in hand, let us state the problem and the **MPC** more formally.\n",
    "\n",
    "###  <font color=\"blue\"> 1.2 MPC mathematical description </font>\n",
    "<a id='2.2'></a>\n",
    "\n",
    "First of all, we consider a controlled physical system described by the system of ordinary differential equations \n",
    "<a id='System'></a>\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\dot{\\boldsymbol x} = \\boldsymbol f(\\boldsymbol x, \\boldsymbol u)\\\\\n",
    "\\boldsymbol y = h(\\boldsymbol x) \\\\\n",
    "\\boldsymbol x(0)=\\boldsymbol x_{0}\\\\\n",
    "\\end{cases}\n",
    "\\end{equation} where $x_{0}$ is the **initial state**.In the following table we introduce some basic notation. From now on, we will write vectors in **bold**.\n",
    "<a id='Notation'></a>\n",
    "\n",
    "| Notation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| Description |\n",
    "|:-----------------------:|-------------|\n",
    "| $\\boldsymbol f(\\cdot, \\cdot) : \\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ |A **state dynamic function** or, more informally, **righ-hand-side** of a system <br /> of ordinary differential equations $\\dot{\\boldsymbol x} = \\boldsymbol f(\\boldsymbol x, \\boldsymbol u)$|\n",
    "| $\\boldsymbol x \\in \\mathbb{R}^{n} $ | An element of the **state space** of a controlled system of dimensionality $n$ |\n",
    "| $\\boldsymbol u \\in \\mathbb{R}^{m}$ | An element of the **action space** of a controlled system of dimensionality $m$ |\n",
    "| $\\boldsymbol y \\in \\mathbb{R}^{k}$ | An **observartion**|\n",
    "| $\\mathbb{X}\\subset \\mathbb{R}^{n} $| **State constraint set**|\n",
    "| $\\mathbb{U}\\subset \\mathbb{R}^{m} $| **Action constraint set**|\n",
    "| $\\boldsymbol h(\\cdot): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{k}$ | **Observation function**  |\n",
    "| $\\kappa(\\cdot) : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ | **Policy** function |\n",
    "| $\\rho(\\cdot) : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ | **Stage cost** function  |\n",
    "| $J_N(\\cdot, \\cdot): \\mathbb{R}^n \\times \\mathcal{K} \\rightarrow \\mathbb{R}$| **N-step cost** (might be refered as **actor cost** either), <br /> where $\\mathcal{K}$ is some functional space of admissible policies |\n",
    "| $\\delta$ | **Sampling time** |\n",
    "| $\\boldsymbol x_k$   | A **state** at time $k\\delta$: $\\qquad\\boldsymbol x (k \\delta)$   |\n",
    "\n",
    "Here we would like to make a few clarifications on the notation introduced.\n",
    "* For **MPC** N-step cost has the following form  $J_N(\\boldsymbol x_{k}, \\kappa(\\cdot)):=\\int_{k\\delta}^{(k+N)\\delta}\\rho(\\boldsymbol x(t), \\kappa(\\boldsymbol x(t))) dt$\n",
    "* In the following problems we consider $\\mathbb{X} = \\mathbb{R}^{n}$ without any remarks but in general we might want to introduce some reasonable **state constraint set**.\n",
    "* When working with the system, we cannot know the exact value of the characteristics we are interested in. What we do is **make a measurement** calculatung **observation function** $\\boldsymbol h(\\cdot)$. The result we call an **observation** $\\boldsymbol y$. For now we consider $\\boldsymbol y = \\boldsymbol h(\\boldsymbol x) := \\boldsymbol x$ further but in general it might not be so! For example, if we control a body motion on a plane $(x,y)$, we could measure a distance to the origin: $\\boldsymbol h(\\boldsymbol x) = \\lVert \\boldsymbol x \\rVert$. \n",
    "* Most modern controllers are digital, therefore the control signal is generated by sampling with some **sampling time** $\\delta$. In that case we call it **digital control setting**. The following table gives a comparison between mathematical description of the original setting of the controlled system and its **digital control setting**.\n",
    "<a id='Comparison_table'></a>\n",
    "|  Original setting | Digital control setting |\n",
    "|:-----------------------|:--------------------------|\n",
    "|1) $ \\qquad \\dot{\\boldsymbol x}=\\boldsymbol f\\left(\\boldsymbol x, \\boldsymbol u\\right) $ | $\\text{1*)} \\quad \\dot{\\boldsymbol x}=\\boldsymbol f\\left(\\boldsymbol x, \\boldsymbol u^{\\delta}\\right)$|\n",
    "| $\\text{2)} \\quad \\boldsymbol u=\\boldsymbol u(t), t \\in[0, T]$  | $\\text{2*)} \\quad \\boldsymbol u_k(t)=\\boldsymbol u(k\\delta) , t \\in[k \\delta,(k+1) \\delta]$  | \n",
    "| $$\\text{3)} \\quad \\boldsymbol x(t):=\\boldsymbol x_{t_0}+\\int_{t_0}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u(\\tau) \\right) d \\tau$$| $$\\text{3*)} \\quad \\boldsymbol x^{\\boldsymbol u_{k}}(t):=\\boldsymbol x_{k}+\\int_{k \\delta}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u_{k}\\right) d \\tau$$|     \n",
    "\n",
    "<!--- $$\\boldsymbol x_{i \\mid k}:=\\boldsymbol x((k+i-1) \\delta), k \\in \\mathbb{N}$$\n",
    "$\\boldsymbol u^{\\delta}(t) \\equiv \\boldsymbol u_{i \\mid k}=\\kappa\\left(\\boldsymbol x_{i \\mid k}\\right), t \\in[k \\delta,(k+i) \\delta]$ \n",
    "One can see that for any $k \\in \\mathbb{N}$, the state $x^{u_{k}}(t)$ at $t \\geq k \\delta$ under $u_{k}$ satisfies\n",
    "-->\n",
    "<p style=\"text-align: center;\">\n",
    "\n",
    "</p>\n",
    "\n",
    "From now and on by the system we mean a system in the **digital control setting**, which is illustrated on the figure below .\n",
    "<img src=\"digital_control_setting.svg\" width=40% height=40% />\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In general, our optimal control problem is written as $\\min_{\\kappa(\\cdot)}\\int_{k\\delta}^{(k+N)\\delta}\\rho(\\boldsymbol x(t), \\kappa(\\boldsymbol x(t))) dt$, where $N$ is **prediction horizon**. But in **MPC** we switch to a discrete sum instead of an integral: $$\\min _{\\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=1}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\delta \\right) $$ Wich is obviously equivalent to the following form:\n",
    "$$\\min _{ \\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=1}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\right)$$  \n",
    "And now we see that it fits conviniently in our **digital control setting**: we will just find a minimizing sequence of actions for our digital model predictive control for stage costs predicted for N steps forward.  Notice that under digital control our state evolves according to [3*)](#Comparison_table) . Now we need to somehow numerically evaluate the interal $\\int_{k \\delta}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u_{k}\\right) d \\tau$. In order to do this one might use any numerical integration scheme. For example the **Euler scheme** :\n",
    "<a id='Euler'></a>\n",
    "$$\n",
    "\\boldsymbol x_{k+1}=\\boldsymbol x_{k}+\\delta \\boldsymbol f\\left(\\boldsymbol x_{k}, \\boldsymbol u_{k}\\right) \\text {, }\n",
    "$$\n",
    "#### Algorithm <sup>[1]</sup>:\n",
    "<a id='Objective'></a>\n",
    "Let us describe the **MPC** algorithm for the problem just described above.  \n",
    "At the current state $\\boldsymbol x_{k}$ :\n",
    "\n",
    "(a) **MPC** solves an $N$-step lookahead  problem: $\\min _{\\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=0}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\right)$\n",
    "\n",
    "(b) If $\\left\\{\\boldsymbol u^{*}_{k}, \\ldots, \\boldsymbol u^{*}_{k+N-1}\\right\\}$ is the optimal control sequence of this problem, **MPC** applies $\\boldsymbol u^{*}_{k}$ and discards the other controls $\\boldsymbol u^{*}_{k+1}, \\ldots, \\boldsymbol u^{*}_{k+N-1}$. \n",
    "\n",
    "(c) At the next stage, **MPC** repeats this process, once the next state $\\boldsymbol x_{k}$ is revealed.\n",
    "\n",
    "\n",
    "<img src=\"MPC.svg\" width=35% height=35% />\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155532e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 2: Problems </h2>\n",
    "\n",
    "In the following, for testing, we will use a system representing a three-wheeled robot described by a system of equations\n",
    "$$\\begin{cases}\n",
    "\\dot{x}_c=v \\cos \\alpha \\\\\n",
    "\\dot{y}_c=v \\sin \\alpha \\\\\n",
    "\\dot{\\alpha}=\\omega\n",
    "\\end{cases}$$ where $x_c$ and $y_c$ are coordinates of the center of mass, $v$ and $\\omega$ are velocity of the center of mass and angular velocity respectively and these are components of the control $\\boldsymbol u := (v, \\omega)$ as well.  \n",
    "\n",
    "***\n",
    "\n",
    "### <font color=\"blue\"> 2.1 Preparation of environment </font>\n",
    "So, let's get started! The cell below contains some imports from Rcognita submodule that was cloned into your current directory in case you did everything correctly. Execute the following code and check out you don't have any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a67786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY\n",
    "\"\"\"\n",
    "import warnings\n",
    "with warnings.catch_warnings(record=True):\n",
    "    import extras\n",
    "    import matplotlib.animation as animation\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from rcognita.rcognita import simulator\n",
    "    from rcognita.rcognita import systems\n",
    "    from rcognita.rcognita import controllers\n",
    "    from rcognita.rcognita import loggers\n",
    "    from rcognita.rcognita import visuals\n",
    "    from rcognita.rcognita.utilities import on_key_press\n",
    "    from rcognita.rcognita.utilities import dss_sim\n",
    "    from rcognita.rcognita.utilities import rep_mat\n",
    "    from rcognita.rcognita.utilities import uptria2vec\n",
    "    from rcognita.rcognita.utilities import push_vec\n",
    "    from scipy.optimize import minimize\n",
    "    import scipy as sp\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185a7ab",
   "metadata": {},
   "source": [
    "#### Configuration and arguments\n",
    "The code below is using `extras.py`file contains default arguments using for preset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de138d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The parser below is defined in the respective argparser_*.py file\n",
    "You can familiarize yourself with default arguments using this file. \n",
    "Change the code only if you really know what you are doing.\n",
    "\"\"\"\n",
    "args = extras.parser.parse_args(['--ctrl_mode','MPC'])\n",
    "\n",
    "if not isinstance(args.state_init[0], int):\n",
    "    for k in range(len(args.state_init)):\n",
    "        args.state_init[k] = eval( args.state_init[k].replace('pi', str(np.pi)) )\n",
    "\n",
    "args.state_init = np.array(args.state_init)\n",
    "args.action_manual = np.array(args.action_manual)\n",
    "dim_state = 3\n",
    "args.dim_state = dim_state\n",
    "args.state_init = np.array(args.state_init)\n",
    "args.action_manual = np.array(args.action_manual)\n",
    "args.dim_state = 3\n",
    "args.dim_input = 2\n",
    "args.dim_output = args.dim_state\n",
    "args.dim_disturb = 0\n",
    "args.grade1 = 0\n",
    "args.grade2 = 1\n",
    "\n",
    "args.dim_R1 = args.dim_output + args.dim_input\n",
    "args.dim_R2 = args.dim_R1\n",
    "args.pred_step_size = args.dt * args.pred_step_size_multiplier\n",
    "\n",
    "args.R1 = np.diag(np.array(args.R1_diag))\n",
    "args.R2 = np.diag(np.array(args.R2_diag))\n",
    "assert args.t1 > args.dt > 0.0\n",
    "assert args.state_init.size == dim_state\n",
    "globals().update(vars(args))\n",
    "is_disturb = 0\n",
    "is_dyn_ctrl = 0\n",
    "\n",
    "t0 = 0\n",
    "\n",
    "action_init = 0 * np.ones(dim_input)\n",
    "\n",
    "# Solver\n",
    "atol = 1e-5\n",
    "rtol = 1e-3\n",
    "\n",
    "# xy-plane\n",
    "xMin = -10\n",
    "xMax = 10\n",
    "yMin = -10\n",
    "yMax = 10\n",
    "\n",
    "# Control constraints\n",
    "v_min = -25\n",
    "v_max = 25\n",
    "omega_min = -5\n",
    "omega_max = 5\n",
    "ctrl_bnds=np.array([[v_min, v_max], [omega_min, omega_max]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512495ac",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.2 Problem 1 | Actor cost computation </font>\n",
    "\n",
    "***\n",
    "\n",
    "In this section we will implement the `_actor_cost` method that basically does two things:\n",
    "1. Given a sequence of $N$ actions, it **computes the resulting sequence of N predicted observations**.\n",
    "2. Given the previously obtained sequence of $N$ observations it **computes and returns $N$-step cost** \n",
    "\n",
    "**Input data**:\n",
    "* `action_sqn` - **action** sequence\n",
    "$\n",
    "\\left(\\begin{array}{c} \n",
    "v^1 \\\\ \n",
    "\\omega^1 \\\\\n",
    "\\vdots \\\\\n",
    "v^N \\\\ \n",
    "\\omega^N \\\\\n",
    "\\end{array}\\right)\n",
    "$\n",
    "where $v^i$ and $\\omega^i$ are velocity of the center of mass and angular velocity respectively. **Dimension**:`[dim_input*N,]`\n",
    "\n",
    "* `observation` - An initial **observation** vector \n",
    "$\n",
    "\\left(\\begin{array}{c} \n",
    "x_c(k\\delta) \\\\ \n",
    "y_c(k\\delta) \\\\\n",
    "\\alpha(k\\delta)\\\\\n",
    "\\end{array}\\right)\n",
    "$\n",
    " for some $k$, from which calculation of prediction starts. **Dimension**:`[dim_output,]` (recall `dim_output`$=3$)\n",
    "\n",
    "**Output data**:\n",
    "* `J` - $N$-step cost. A `float` value.\n",
    "\n",
    "***\n",
    "\n",
    "Here are a few essential tips for this problem:\n",
    "* `self.state_sys -> numpy.ndarray` - An **observation** $\\boldsymbol y$ of the [system](#System) from which prediction starts (Keep in mind that $\\boldsymbol h(\\boldsymbol x):=\\boldsymbol x$). **Dimension**: `[dim_output,]`\n",
    "*  **Action** has a **dimension**  `[dim_input,]`\n",
    "* `self.sys_rhs(t, state, action) -> np.ndarray` returns a value of the [**state dynamic function**](#System) .  (_Our dynamical system doesn't depend on time explicitly. So, pass an empty list instead, for example:_ `self.sys_rhs([], var, var)`).\n",
    "* `self.Nactor -> int` is the **prediction horizon** (number of steps denoted by $N$ in the algorithm description in the section [1.2](#2.2))\n",
    "* `self.pred_step_size -> float` is the **step size** $\\delta$\n",
    "* `self.stage_obj(observation, action) -> float` is the **stage objective** $\\rho \\left(\\boldsymbol x_{k+i}, \\boldsymbol u_{k+i}\\right)$\n",
    "* You can choose any suitable numerical integration method to compute corresponding integral $ \\boldsymbol x^{u_{k}}(t):=\\boldsymbol x_{k}+\\int_{k \\delta}^{t} \\boldsymbol f\\left(\\boldsymbol x(\\tau), \\boldsymbol u_{k}\\right) d \\tau $ to obtain state prediction for further total cost calculation. For example, [Euler scheme](#Euler)\n",
    "\n",
    "***\n",
    "\n",
    "**Due to grading purposes, please create a  variable `observation_sqn` and store all states in it. It should be an `np.ndarray` and have a dimension of `[N, dim_output]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CtrlOptPredWithoutOptimizer(controllers.CtrlOptPred):\n",
    "    def _actor_cost(self, action_sqn, observation):\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "        \n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "        \n",
    "        self.observation_sqn = observation_sqn\n",
    "        \n",
    "        return J # J -- N-step cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f089d",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.3 Problem 1 | Testing of the N-step cost method implementation </font>\n",
    "\n",
    "***\n",
    "\n",
    "Executing of the following cell invokes a test procedure for **N-step cost** computation. There is reference data that was generated for grading of the assignment. So, all grades are based on unit-tests with the following parameters:\n",
    "\n",
    "* **Prediction horizon** $N = 30$\n",
    "* 3 action sequences of lenght 30\n",
    "\n",
    "\n",
    "It creates a report with the following structure: \n",
    "* $l_1$-difference metric\n",
    "* $l_2$-difference metric\n",
    "* $l_\\infty$-difference metric\n",
    "* Plots of reference and test predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d90732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_sys = systems.Sys3WRobotNI(sys_type=\"diff_eqn\",\n",
    "                                     dim_state=dim_state,\n",
    "                                     dim_input=dim_input,\n",
    "                                     dim_output=dim_output,\n",
    "                                     dim_disturb=dim_disturb,\n",
    "                                     pars=[],\n",
    "                                     ctrl_bnds=10*np.array([[-1,-1],[1,1]]),\n",
    "                                     is_dyn_ctrl=0,\n",
    "                                     is_disturb=0,\n",
    "                                     pars_disturb=[])\n",
    "\n",
    "\n",
    "\n",
    "test_controller = CtrlOptPredWithoutOptimizer(dim_input=dim_input,\n",
    "                                dim_output=dim_output,\n",
    "                                ctrl_bnds = 10*np.array([[-1,-1],[1,1]]),\n",
    "                                action_init = [],\n",
    "                                t0 = 0,\n",
    "                                sampling_time = 0.01,\n",
    "                                Nactor = 30,\n",
    "                                pred_step_size = 0.01,\n",
    "                                sys_rhs = my_sys._state_dyn,\n",
    "                                sys_out = my_sys.out,\n",
    "                                state_sys = state_init,\n",
    "                                gamma = 1,\n",
    "                                stage_obj_struct = stage_obj_struct,\n",
    "                                stage_obj_pars = [R1],\n",
    "                                observation_target = [])\n",
    "\n",
    "ref_observations = extras.generate_data_for_task(test_controller)\n",
    "grade1 = extras.test_first_task_procedure(test_controller, ref_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775a8b9",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.4 Problem 2 | Implementation of actor optimizer method. </font>\n",
    "\n",
    "In this section we implement the `_actor_optimizer()` method that performs the constrained minimization of the $N$-step cost: $$\\min _{\\boldsymbol u_{k+i}: i=0, \\ldots, N-1} \\left(\\sum_{i=0}^{N-1} \\rho \\left(\\hat{\\boldsymbol  x}_{k+i}, \\boldsymbol u_{k+i}\\right)\\right)\\\\\n",
    " \\quad \\boldsymbol u_{k+i} \\in U\n",
    "$$\n",
    "\n",
    "Where $U$ is the ation constraints set.\n",
    "\n",
    "**Input data**:\n",
    "\n",
    "* `observation` - An initial **observation** vector $\\boldsymbol y_k =$\n",
    "$\n",
    "\\left(\\begin{array}{c} \n",
    "x_c(k\\delta) \\\\ \n",
    "y_c(k\\delta) \\\\\n",
    "\\alpha(k\\delta)\\\\\n",
    "\\end{array}\\right)\n",
    "$\n",
    " for some $k$, from which calculation of prediction starts. **Dimension**:`[dim_output,]` (recall `dim_output`$=3$)\n",
    "\n",
    "**Output data**:\n",
    "* `action_sqn` - **action** sequence $[\\boldsymbol u_1, \\dots , \\boldsymbol u_N] =$\n",
    "$\n",
    "\\left(\\begin{array}{c} \n",
    "v^1 \\\\ \n",
    "\\omega^1 \\\\\n",
    "\\vdots \\\\\n",
    "v^N \\\\ \n",
    "\\omega^N \\\\\n",
    "\\end{array}\\right)\n",
    "$\n",
    "where $v^i$ and $\\omega^i$ are velocity of the center of mass and angular velocity respectively. **Dimension**:`[dim_input*N,]`\n",
    "\n",
    "Here are a few tips for this problem as well:\n",
    "* To compute the $N$-step cost use previously implemented method `_actor_cost()`\n",
    "* Using `sp.optimize.Bounds` implement constraints set $U$ for our optimization problem. Exact minimum and maximum values of action you can obtain using `self.action_sqn_min` and `self.action_sqn_max`\n",
    "* Choose suitable hyperparameters for optimization. For example, `tolerance`, `max_iter`, `method` and so on. \n",
    "* To solve this problem you may use SciPy otimizer. Examine [docs](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) of the corresponding minimizator and apply it to `_actor_cost()`\n",
    "* `self.dim_input` is the dimensionality of action\n",
    "* Don't forget you need to return only the **first action**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CtrlOptPredStudent(CtrlOptPredWithoutOptimizer):\n",
    "    def _actor_optimizer(self, observation):\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "               \n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "        return action_sqn[:self.dim_input]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2672368",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.5 Problem 2 | Testing of the implemented controller </font>\n",
    "\n",
    "Launch all the following code after the controller is implemented. You will see the final results of your work in the end of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6250870",
   "metadata": {},
   "source": [
    "#### System initialization\n",
    "\n",
    "In the following cell we will instantiate a 3-wheel robot system for controller testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fed0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sys = systems.Sys3WRobotNI(sys_type=\"diff_eqn\",\n",
    "                                     dim_state=dim_state,\n",
    "                                     dim_input=dim_input,\n",
    "                                     dim_output=dim_output,\n",
    "                                     dim_disturb=dim_disturb,\n",
    "                                     pars=[],\n",
    "                                     ctrl_bnds=ctrl_bnds,\n",
    "                                     is_dyn_ctrl=is_dyn_ctrl,\n",
    "                                     is_disturb=is_disturb,\n",
    "                                     pars_disturb=[])\n",
    "\n",
    "observation_init = my_sys.out(state_init)\n",
    "\n",
    "xCoord0 = state_init[0]\n",
    "yCoord0 = state_init[1]\n",
    "\n",
    "alpha0 = state_init[2]\n",
    "alpha_deg_0 = alpha0/2/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ee76e",
   "metadata": {},
   "source": [
    "#### Implemented controller initialization\n",
    "\n",
    "In the following code we create an instance of the class of the controller you implemented earlier. It will be used in the final test in the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ctrl_opt_pred = CtrlOptPredStudent(dim_input=dim_input,\n",
    "                                dim_output=dim_output,\n",
    "                                ctrl_bnds = ctrl_bnds,\n",
    "                                action_init = [],\n",
    "                                t0 = t0,\n",
    "                                sampling_time = dt,\n",
    "                                Nactor = Nactor,\n",
    "                                pred_step_size = pred_step_size,\n",
    "                                sys_rhs = my_sys._state_dyn,\n",
    "                                sys_out = my_sys.out,\n",
    "                                state_sys = state_init,\n",
    "                                gamma = gamma,\n",
    "                                stage_obj_struct = stage_obj_struct,\n",
    "                                stage_obj_pars = [R1],\n",
    "                                observation_target = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565533a",
   "metadata": {},
   "source": [
    "#### Simulator initialization\n",
    "\n",
    "Simulator is a module of Rcognita framework which performs simulation of closed loops. Below we create an instance of the `Simulator` class and to use it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator = simulator.Simulator(sys_type = \"diff_eqn\",\n",
    "                                   closed_loop_rhs = my_sys.closed_loop_rhs,\n",
    "                                   sys_out = my_sys.out,\n",
    "                                   state_init = state_init,\n",
    "                                   disturb_init = [],\n",
    "                                   action_init = action_init,\n",
    "                                   t0 = t0,\n",
    "                                   t1 = t1,\n",
    "                                   dt = dt,\n",
    "                                   max_step = dt/2,\n",
    "                                   first_step = 1e-6,\n",
    "                                   atol = atol,\n",
    "                                   rtol = rtol,\n",
    "                                   is_disturb = is_disturb,\n",
    "                                   is_dyn_ctrl = is_dyn_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb9fd6",
   "metadata": {},
   "source": [
    "####  Main loop\n",
    "\n",
    "This is a main part of testing procedure. \n",
    "Here are two main parameters:\n",
    "* `is_visualization` - if `False`, raw simulation steps are printed. Use this flag to debug your code\n",
    "* `verbosity_level = N` to print every `N`-th simulation step, to make debug output calm and nice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e38bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Just to make things work\n",
    "state_full_init = my_simulator.state_full\n",
    "my_logger = loggers.Logger3WRobotNI()\n",
    "full_trajectory = []\n",
    "datafiles = [None] * Nruns\n",
    "my_logger = loggers.Logger3WRobotNI()\n",
    "my_ctrl_nominal = controllers.CtrlNominal3WRobotNI(ctrl_gain=0.5, ctrl_bnds=ctrl_bnds, \n",
    "                                                                  t0=t0, \n",
    "                                                                  sampling_time=dt)\n",
    "my_ctrl_benchm = my_ctrl_opt_pred\n",
    "step_number = 0\n",
    "\n",
    "################# Debug\n",
    "is_visualization = True\n",
    "verbosity_level = 200\n",
    "#####################\n",
    "\n",
    "if is_visualization:\n",
    "    my_animator = extras.Animator3WRobotNI_traj(objects=(my_simulator,\n",
    "                                                     my_sys,\n",
    "                                                     controllers.CtrlNominal3WRobotNI(ctrl_gain=0.5, \n",
    "                                                                                      ctrl_bnds=ctrl_bnds, \n",
    "                                                                                      t0=t0, \n",
    "                                                                                      sampling_time=dt),\n",
    "                                                     my_ctrl_opt_pred,\n",
    "                                                     [None] * Nruns,\n",
    "                                                     controllers.ctrl_selector,\n",
    "                                                     my_logger),\n",
    "                                            pars=(state_init,\n",
    "                                                  action_init,\n",
    "                                                  t0,\n",
    "                                                  t1,\n",
    "                                                  state_full_init,\n",
    "                                                  xMin,\n",
    "                                                  xMax,\n",
    "                                                  yMin,\n",
    "                                                  yMax,\n",
    "                                                  'MPC',\n",
    "                                                  action_manual,\n",
    "                                                  v_min,\n",
    "                                                  omega_min,\n",
    "                                                  v_max,\n",
    "                                                  omega_max,\n",
    "                                                  Nruns,\n",
    "                                                    is_print_sim_step, is_log_data, 0, []))\n",
    "\n",
    "    anm = animation.FuncAnimation(my_animator.fig_sim,\n",
    "                                  my_animator.animate,\n",
    "                                  init_func=my_animator.init_anim,\n",
    "                                  blit=False, interval=dt/1e6, repeat=False)\n",
    "\n",
    "    my_animator.get_anm(anm)\n",
    "\n",
    "    cId = my_animator.fig_sim.canvas.mpl_connect('key_press_event', lambda event: on_key_press(event, anm))\n",
    "\n",
    "    anm.running = True\n",
    "\n",
    "    my_animator.fig_sim.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:   \n",
    "    run_curr = 1\n",
    "    datafile = datafiles[0]\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        my_simulator.sim_step()\n",
    "        \n",
    "        t, state, observation, state_full = my_simulator.get_sim_step_data()\n",
    "        \n",
    "        action = controllers.ctrl_selector(t, observation, action_manual, my_ctrl_nominal, my_ctrl_benchm, ctrl_mode)\n",
    "        \n",
    "        my_sys.receive_action(action)\n",
    "        my_ctrl_benchm.receive_sys_state(my_sys._state)\n",
    "        my_ctrl_benchm.upd_accum_obj(observation, action)\n",
    "        \n",
    "        xCoord = state_full[0]\n",
    "        yCoord = state_full[1]\n",
    "        alpha = state_full[2]\n",
    "        \n",
    "        stage_obj = my_ctrl_benchm.stage_obj(observation, action)\n",
    "        accum_obj = my_ctrl_benchm.accum_obj_val\n",
    "        \n",
    "        if is_print_sim_step & (step_number % verbosity_level == 0):\n",
    "            my_logger.print_sim_step(t, xCoord, yCoord, alpha, stage_obj, accum_obj, action)\n",
    "            \n",
    "        if is_log_data:\n",
    "            my_logger.log_data_row(datafile, t, xCoord, yCoord, alpha, stage_obj, accum_obj, action)\n",
    "        step_number += 1\n",
    "        if t >= t1:  \n",
    "            if is_print_sim_step:\n",
    "                print('.....................................Run {run:2d} done.....................................'.format(run = run_curr))\n",
    "                \n",
    "            run_curr += 1\n",
    "            \n",
    "            if run_curr > Nruns:\n",
    "                break\n",
    "                \n",
    "            if is_log_data:\n",
    "                datafile = datafiles[run_curr-1]\n",
    "            \n",
    "            # Reset simulator\n",
    "            my_simulator.status = 'running'\n",
    "            my_simulator.t = t0\n",
    "            my_simulator.observation = state_full_init\n",
    "            \n",
    "            if ctrl_mode != 'nominal':\n",
    "                my_ctrl_benchm.reset(t0)\n",
    "            else:\n",
    "                my_ctrl_nominal.reset(t0)\n",
    "            \n",
    "            accum_obj = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef10f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade2 = extras.integral_grading(my_animator.full_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832a40a",
   "metadata": {},
   "source": [
    "### Grading\n",
    "\n",
    "Run this cell to see the resulting grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34098df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "extras.final_grade(grade1, grade2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9a161",
   "metadata": {},
   "source": [
    "## Questions?\n",
    "\n",
    "Reach out to **Ilya Osokin (@elijahmipt)** or **Georgiy Malaniya (@odinmaniac)** on Telegram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859226f",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    " ***\n",
    " **<sup>[1]</sup> Bertsekas, D. , Reinforcement Learning and Optimal Control**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
